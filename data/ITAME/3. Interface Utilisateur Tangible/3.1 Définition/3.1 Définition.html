<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="generator" content="scholpandoc">
  <meta name="viewport" content="width=device-width">
  
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.7.1/modernizr.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.js"></script>
  <link rel="stylesheet" href="css/scholmd-heuristically-latest.min.css">
</head>
<body>
<div class="scholmd-container">
<div class="scholmd-main">
<div class="scholmd-content">
<h1 id="interface-tangible">Interface tangible</h1>
<h2 id="naissance-shaer2010tangible">Naissance <span class="scholmd-citation" data-cites="shaer2010tangible">[1]</span></h2>
<p>En 1993, une édition spéciale des communications d’ACM titre “Back to the Real World” <span class="scholmd-citation" data-cites="wellner1993back">[2]</span> et affirme que les ordinateurs et la réalité virtuelle éloignent les hommes de leur “environnement naturelle”. Il insinue qu’au lieu de forcer les utilisateurs à entrer dans un monde virtuelle, ce dernier devrait être utilisé pour augmenter et enrichir le monde réel avec des fonctionnalités numériques.</p>
<p>En 1995, Fitzmaurice et al. <span class="scholmd-citation" data-cites="fitzmaurice1995bricks">[3]</span> introduit la notion de “Graspable Interface”, où des objets physiques sont saisissables par l’utilisateur pour manipuler des objets numériques.</p>
<p>En 1997, Ishii et ses étudiants <span class="scholmd-citation" data-cites="ishii1997tangible">[4]</span> présentent les “Tangible bits”. Leur vision est centrée sur la transformation du monde physique en une interface, en connectant les objets et surfaces avec le monde numérique.</p>
<p>En 2001, Ullmer et Ishii définissent les Interfaces Utilisateurs Tangibles comme étant des systèmes qui utilisent des objets physiques pour représenter et manipuler les données numériques. En s’inspirant du célèbre modèle MVC (Model, View, Control), Ulmer et Ishii ont également suggérés un modèle d’interaction appelé MCRit qui est une abréviation pour Model-Control-Représentation (intangible et tangible). Alors que le modèle MVC fait la distinction entre la représentation graphique (i.e. une sortie) et le contrôle (i.e. une entrée), le modèle RCRit met en avant le fait que la distinction entre entrée et sortie dans les Interfaces Utilisateurs Tangibles est confondu par une représentation et un contrôle des données directes dans le monde physique.</p>
<img src="images/mcritmodel.jpg" />
<h4 style="text-align:center">
MCRit Model <span class="scholmd-citation" data-cites="ullmer2000emerging">[5]</span>
</h4>
<h2 id="avantages">Avantages</h2>
<h3 id="la-collaboration">La Collaboration</h3>
<p>Depuis le début, Les Interfaces Utilisateurs Tangibles cherchent à favoriser le dialogue entre les experts (e.g., architecte) et les parties concernées (e.g., futurs habitants du bâtiment) et à supporter l’apprentissage collaboratif.</p>
<h3 id="lapplicabilité">L’applicabilité</h3>
<p>Les Interfaces Utilisateurs Tangibles peuvent exister dans notre monde et se placer dans des contextes précis. En effet, la sémantique d’interaction avec l’interface tangible peut changer en fonction du contexte dans lequel elle se trouve.</p>
<h3 id="la-réflexion-tangible">La réflexion tangible</h3>
<p>Notre corps et les objets physiques avec les quelles nous interagissons jouent un rôle central dans le façonnage de notre compréhension du monde <span class="scholmd-citation" data-cites="klemmer2006bodies">[6]</span>, <span class="scholmd-citation" data-cites="turkle2011evocative">[7]</span>. Les interfaces Utilisateurs Tangibles permette de renforcer cette connexion entre le corps et la cognition en facilitant la réflexion tangible - Réflexion par le biais d’actions, de manipulations physiques, et de représentation tangible.</p>
<h3 id="la-gestuelle">La gestuelle</h3>
<p>Alors que les gestes sont typiquement considérés comme un moyen de communication, plusieurs études illustrent le fait que les gestes jouent un rôle dans l’allégement de la charge cognitive que se soit celle des enfants ou celle des adultes <span class="scholmd-citation" data-cites="alibali2000gesture">[8]</span>. En fournissant aux utilisateurs de multiples points d’accès au système et en maintenant leur mobilité physique.</p>
<h3 id="les-actions-épistémiques-et-accessoires-de-réflexion">Les Actions épistémiques et accessoires de réflexion</h3>
<p>Plusieurs études ont démontrés que les artefacts physiques supportent la cognition en servant d’ “accessoires de réflexion” et de mémoire externes. On distingue les actions pragmatiques qui ont des conséquences fonctionnelles et donc contribuent à l’accomplissement d’un but et les actions épistémiques qui n’ont pas de conséquences fonctionnelles mais plutôt changent la nature de la tache mentale <span class="scholmd-citation" data-cites="kirsh1994distinguishing">[9]</span>. Les actions épistémiques aide à explorer des options, à garder la trace des décisions précédemment prissent, et aide à la mémorisation. Des actions comme pointer un objet, le réarranger, le tourner, le cacher, etc. Les Interfaces Utilisateurs Tangibles cherchent à rendre les actions épistémiques plus facile qu’avec une Interface Utilisateur traditionnelle.</p>
<h3 id="la-représentation-tangible">La représentation tangible</h3>
<p>Il a été démontré que les représentations externes d’informations sont des composantes intrinsèques à beaucoup de tache cognitives car elles guides, contraignent, et même déterminent le comportement cognitif <span class="scholmd-citation" data-cites="zhang1997nature">[10]</span>. Ils existent de nombreux domaines des Interfaces Utilisateurs Tangibles où l’ont utilisent des objets physiques en tant que représentation externes d’informations numériques : architecture, économie, musique, biologie, création, chimie, etc.</p>
<h3 id="le-multiplexage-de-lespace-et-la-spontanéité-de-linteraction.">Le multiplexage de l’espace et la spontanéité de l’interaction.</h3>
<p>Dans les interfaces tangibles qui utilisent plusieurs objets d’interaction, l’entrée de l’information est spatialisée. Les différents objets représentent différentes fonctions ou données. Ceci permet au concepteur du système de prendre avantage de la forme, la taille, et de la position du contrôleur physique pour accroître ses fonctionnalités et réduire la complexité de l’interaction. De plus, Ceci permet un mapping persistante, comparé à une GUI traditionnelle, où chaque clique de souris peut provoquer l’appel d’une fonction ou la sélection d’un objet non souhaité. Plusieurs interacteurs spécifiques permettent des actions parallèles. Au contraire d’une interface classique où l’utilisateur doit séquentiellement effectuer les actions les unes après les autres.</p>
<h2 id="une-incarnation-forte-de-la-données-qui-créer-de-laffordance-et-de-liconicité">Une incarnation forte de la données qui créer de l’affordance et de l’iconicité</h2>
<p>Utiliser plusieurs interacteurs permet de créer des entrées qui ne sont ni génériques, ni abstraites mais spécifiques, dédié par leur forme et leur apparence à une fonctionnalité particulière. L’apparence d’un objet peut directement indiquer sa signification, sa fonctionnalité associée mais également comment interagir avec lui par l’utilisation de l’affordance.</p>
<h2 id="limitations">Limitations</h2>
<h3 id="la-flexibilité-et-le-risque-de-perdre-les-objets-physiques.">La flexibilité et le risque de perdre les objets physiques.</h3>
<p>Des applications réussites des Interfaces Utilisateurs Tangibles pour de petits problèmes ou pour de petits échantillons de données sont rarement applicables à des problèmes plus complexes incluant beaucoup de paramètres et des échantillons de données plus grands. Il y a plusieurs raisons à ce problème : L’espace occupé par les objets physiques de l’Interface Tangible. En effet combien d’objets peuvent être supporter par une surface interactive avant que cette dernière devienne inutilisable. Si cette surface venait à grandir, il serait beaucoup plus difficile pour un utilisateur d’accéder et déplacer les objets car il devrait se déplacer, voir voler, sur la surface. Un autre problème est la forme extrême de manipulation donnée par les Interfaces Utilisateurs Tangibles aux données, cette dernière ne permet pas à l’utilisateur d’accéder et de modifier des variables internes à la données comme le ferai simplement une ligne de commande dans une interface traditionnelle <span class="scholmd-citation" data-cites="bellotti2002making">[11]</span>.</p>
<h3 id="la-polyvalence-et-la-malléabilité">La polyvalence et la malléabilité</h3>
<p>Les données numériques sont malléables, facile à créer, modifier, répliquer, et à distribuer, les objets physiques quand à eux sont rigides et statiques <span class="scholmd-citation" data-cites="poupyrev2007actuation">[12]</span>. Un interface utilisateur graphique peut etre utilisé pour effectuer une variété de tâches tels que l’écriture de document, chatter avec des amis, et jouer de la musique. Cependant, une Interface Utilisateur Tangible est typiquement conçue pour un panel de tâche limité. De plus, une interface utilisateur graphique permet à l’utilisateur de changer de vue ou de représentations (e.g., de la vue carte à la vue satellite). Avec une Interface Utilisateur Tangible un tel changement est difficile du fait que la représentation tangible est déja choisie.</p>
<h2 id="la-fatigue">La fatigue</h2>
<p>Les effets de la taille et du poids des objets tangibles ne doit pas être sous-estimé. Le design physique de l’objet ne devrait pas seulement considéré l’affordance en terme d’actions que l’utilisateur est invité à effectuer par la forme physique de l’objet, mais aussi l’ergonomie et la durée potentielle d’utilisation de l’objet tangible.</p>
<div class="references">
<h2>Références</h2>
<p>1. Shaer O, Hornecker E (2010) Tangible user interfaces: Past, present, and future directions. Foundations and Trends in Human-Computer Interaction 3: 1‑137.</p>
<p>2. Wellner P, Mackay W, Gold R (1993) Back to the real world. Communications of the ACM 36: 24‑26.</p>
<p>3. Fitzmaurice GW, Ishii H, Buxton WA (1995) Bricks: Laying the foundations for graspable user interfaces. In: Proceedings of the sIGCHI conference on human factors in computing systems. ACM Press/Addison-Wesley Publishing Co. p. 442‑449.</p>
<p>4. Ishii H, Ullmer B (1997) Tangible bits: Towards seamless interfaces between people, bits and atoms. In: Proceedings of the aCM sIGCHI conference on human factors in computing systems. ACM. p. 234‑241.</p>
<p>5. Ullmer B, Ishii H (2000) Emerging frameworks for tangible user interfaces. IBM systems journal 39: 915‑931.</p>
<p>6. Klemmer SR, Hartmann B, Takayama L (2006) How bodies matter: Five themes for interaction design. In: Proceedings of the 6th conference on designing interactive systems. ACM. p. 140‑149.</p>
<p>7. Turkle S (2011) Evocative objects: Things we think with. MIT press.</p>
<p>8. Alibali MW, Kita S, Young AJ (2000) Gesture and the process of speech production: We think, therefore we gesture. Language and cognitive processes 15: 593‑613.</p>
<p>9. Kirsh D, Maglio P (1994) On distinguishing epistemic from pragmatic action. Cognitive science 18: 513‑549.</p>
<p>10. Zhang J (1997) The nature of external representations in problem solving. Cognitive science 21: 179‑217.</p>
<p>11. Bellotti V, Back M, Edwards WK, Grinter RE, Henderson A, et al. (2002) Making sense of sensing systems: Five questions for designers and researchers. In: Proceedings of the sIGCHI conference on human factors in computing systems. ACM. p. 415‑422.</p>
<p>12. Poupyrev I, Nashida T, Okabe M (2007) Actuation and tangible user interfaces: The vaucanson duck, robots, and shape displays. In: Proceedings of the 1st international conference on tangible and embedded interaction. ACM. p. 205‑212.</p>
</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
      processClass: "math"
    },
    TeX: {
        TagSide: "left",
        TagIndent: "1.2em",
        equationNumbers: {
            autoNumber: "AMS"
        },
        Macros: {
            ensuremath: ["#1",1],
            textsf: ["\\mathsf{\\text{#1}}",1],
            texttt: ["\\mathtt{\\text{#1}}",1]
        }
    },
    "HTML-CSS": { 
        scale: 100,
        availableFonts: ["TeX"], 
        preferredFont: "TeX",
        webFont: "TeX",
        imageFont: "TeX",
        EqnChunk: 1000
    }
});
</script>
</div>
</body>
</html>
